{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -U pip setuptools wheel\n",
    "!pip install -r ../requirements.txt\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Wavelet21 Method Example\n",
    "\n",
    "This notebook demonstrates the Wavelet21 method for structural breakpoint detection using wavelet decomposition and frequency domain analysis.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup: import from local package (fixed path)\n",
    "import sys, pathlib\n",
    "\n",
    "# Import standard libraries first to avoid conflicts\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Add the parent of the repository root to sys.path so `StructualBreakV2` is importable\n",
    "repo_parent = pathlib.Path().resolve().parent.parent\n",
    "if str(repo_parent) not in sys.path:\n",
    "    sys.path.insert(0, str(repo_parent))\n",
    "\n",
    "from StructualBreakV2 import compute_predictors_for_values, run_batch, Wavelet21Method\n",
    "print(\"Imports OK.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create synthetic data with structural break\n",
    "np.random.seed(42)\n",
    "n = 200\n",
    "\n",
    "# Create time series with structural break at t=100\n",
    "t = np.arange(n)\n",
    "# Pre-break: AR(1) with low variance\n",
    "x_pre = np.random.normal(0, 0.5, 100)\n",
    "for i in range(1, 100):\n",
    "    x_pre[i] = 0.7 * x_pre[i-1] + np.random.normal(0, 0.5)\n",
    "\n",
    "# Post-break: AR(1) with higher variance and different mean\n",
    "x_post = np.random.normal(2, 1.0, 100)\n",
    "for i in range(1, 100):\n",
    "    x_post[i] = 0.3 * x_post[i-1] + np.random.normal(2, 1.0)\n",
    "\n",
    "# Combine series\n",
    "values = np.concatenate([x_pre, x_post])\n",
    "periods = np.concatenate([np.zeros(100), np.ones(100)])\n",
    "\n",
    "print(f\"Created synthetic time series with {len(values)} observations\")\n",
    "print(f\"Structural break at t=100 (index 100)\")\n",
    "print(f\"Pre-break mean: {np.mean(values[:100]):.3f}, std: {np.std(values[:100]):.3f}\")\n",
    "print(f\"Post-break mean: {np.mean(values[100:]):.3f}, std: {np.std(values[100:]):.3f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the synthetic data\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(t, values, 'b-', linewidth=1, label='Time Series')\n",
    "plt.axvline(x=100, color='r', linestyle='--', alpha=0.7, label='True Break Point')\n",
    "plt.xlabel('Time')\n",
    "plt.ylabel('Value')\n",
    "plt.title('Synthetic Time Series with Structural Break')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test Wavelet21 method on single series\n",
    "print(\"Testing Wavelet21 method...\")\n",
    "\n",
    "# Method 1: Using the main API\n",
    "predictors, metadata = compute_predictors_for_values(\n",
    "    values, periods, method='wavelet21'\n",
    ")\n",
    "\n",
    "print(f\"\\nMethod: {metadata['method']}\")\n",
    "print(f\"Status: {metadata['status']}\")\n",
    "print(f\"Processing time: {metadata['processing_time']:.3f} seconds\")\n",
    "print(f\"Number of observations: {metadata['n_observations']}\")\n",
    "\n",
    "print(f\"\\nKey Predictors:\")\n",
    "print(f\"  p_wavelet_break: {predictors.get('p_wavelet_break', 'N/A'):.3f}\")\n",
    "print(f\"  confidence: {predictors.get('confidence', 'N/A'):.3f}\")\n",
    "print(f\"  S_local_max_over_j: {predictors.get('S_local_max_over_j', 'N/A'):.3f}\")\n",
    "print(f\"  cnt_local_sum_over_j: {predictors.get('cnt_local_sum_over_j', 'N/A')}\")\n",
    "print(f\"  log_energy_ratio_l2norm_over_j: {predictors.get('log_energy_ratio_l2norm_over_j', 'N/A'):.3f}\")\n",
    "\n",
    "print(f\"\\nResidual Diagnostics:\")\n",
    "print(f\"  resid_kurtosis: {predictors.get('resid_kurtosis', 'N/A'):.3f}\")\n",
    "print(f\"  resid_skewness: {predictors.get('resid_skewness', 'N/A'):.3f}\")\n",
    "print(f\"  arch_lm_p: {predictors.get('arch_lm_p', 'N/A'):.3f}\")\n",
    "\n",
    "print(f\"\\nSegment Shifts:\")\n",
    "print(f\"  mean_diff: {predictors.get('mean_diff', 'N/A'):.3f}\")\n",
    "print(f\"  log_var_ratio: {predictors.get('log_var_ratio', 'N/A'):.3f}\")\n",
    "print(f\"  ks_p_raw: {predictors.get('ks_p_raw', 'N/A'):.3f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Method 2: Direct instantiation of Wavelet21Method\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"Testing direct Wavelet21Method instantiation...\")\n",
    "\n",
    "# Create Wavelet21 method instance\n",
    "wavelet21 = Wavelet21Method()\n",
    "\n",
    "# Get method information\n",
    "info = wavelet21.get_method_info()\n",
    "print(f\"\\nMethod Information:\")\n",
    "for key, value in info.items():\n",
    "    print(f\"  {key}: {value}\")\n",
    "\n",
    "# Test on the same data\n",
    "predictors2, metadata2 = wavelet21.compute_predictors(values, periods)\n",
    "\n",
    "print(f\"\\nDirect Method Results:\")\n",
    "print(f\"  Status: {metadata2['status']}\")\n",
    "print(f\"  Processing time: {metadata2['processing_time']:.3f} seconds\")\n",
    "print(f\"  p_wavelet_break: {predictors2.get('p_wavelet_break', 'N/A'):.3f}\")\n",
    "print(f\"  confidence: {predictors2.get('confidence', 'N/A'):.3f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare with Roy24 method\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"Comparing Wavelet21 with Roy24 method...\")\n",
    "\n",
    "# Test Roy24 method\n",
    "predictors_roy24, metadata_roy24 = compute_predictors_for_values(\n",
    "    values, periods, method='roy24'\n",
    ")\n",
    "\n",
    "print(f\"\\nComparison Results:\")\n",
    "print(f\"{'Metric':<30} {'Wavelet21':<12} {'Roy24':<12}\")\n",
    "print(\"-\" * 54)\n",
    "\n",
    "# Compare key metrics\n",
    "metrics = ['p_wavelet_break', 'confidence']\n",
    "for metric in metrics:\n",
    "    w21_val = predictors.get(metric, 'N/A')\n",
    "    r24_val = predictors_roy24.get(metric, 'N/A')\n",
    "    if isinstance(w21_val, (int, float)) and isinstance(r24_val, (int, float)):\n",
    "        print(f\"{metric:<30} {w21_val:<12.3f} {r24_val:<12.3f}\")\n",
    "    else:\n",
    "        print(f\"{metric:<30} {str(w21_val):<12} {str(r24_val):<12}\")\n",
    "\n",
    "print(f\"\\nProcessing Times:\")\n",
    "print(f\"  Wavelet21: {metadata['processing_time']:.3f} seconds\")\n",
    "print(f\"  Roy24: {metadata_roy24['processing_time']:.3f} seconds\")\n",
    "\n",
    "print(f\"\\nMethod Status:\")\n",
    "print(f\"  Wavelet21: {metadata['status']}\")\n",
    "print(f\"  Roy24: {metadata_roy24['status']}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test with different configurations\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"Testing Wavelet21 with different configurations...\")\n",
    "\n",
    "# Test with custom configuration\n",
    "custom_config = {\n",
    "    'wavelet_type': 'db4',  # Daubechies 4 wavelet\n",
    "    'decomposition_levels': 4,\n",
    "    'alpha': 0.01,  # More stringent threshold\n",
    "    'mc_reps': 200  # Fewer MC repetitions for speed\n",
    "}\n",
    "\n",
    "wavelet21_custom = Wavelet21Method(custom_config)\n",
    "predictors_custom, metadata_custom = wavelet21_custom.compute_predictors(values, periods)\n",
    "\n",
    "print(f\"\\nCustom Configuration Results:\")\n",
    "print(f\"  Wavelet type: {custom_config['wavelet_type']}\")\n",
    "print(f\"  Decomposition levels: {custom_config['decomposition_levels']}\")\n",
    "print(f\"  Alpha: {custom_config['alpha']}\")\n",
    "print(f\"  MC repetitions: {custom_config['mc_reps']}\")\n",
    "print(f\"  Status: {metadata_custom['status']}\")\n",
    "print(f\"  Processing time: {metadata_custom['processing_time']:.3f} seconds\")\n",
    "print(f\"  p_wavelet_break: {predictors_custom.get('p_wavelet_break', 'N/A'):.3f}\")\n",
    "print(f\"  confidence: {predictors_custom.get('confidence', 'N/A'):.3f}\")\n",
    "\n",
    "print(f\"\\nAll MODW Features Available:\")\n",
    "modw_features = [k for k in predictors.keys() if any(x in k for x in ['j1_', 'j2_', 'j3_', 'S_local', 'cnt_', 'log_energy'])]\n",
    "for feature in sorted(modw_features)[:10]:  # Show first 10\n",
    "    print(f\"  {feature}: {predictors.get(feature, 'N/A'):.3f}\")\n",
    "if len(modw_features) > 10:\n",
    "    print(f\"  ... and {len(modw_features) - 10} more MODW features\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Real-data subset demo (Wavelet21) â€” edit the paths/params below\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "\n",
    "# Inputs and params\n",
    "INPUT_PARQUET = '../_tmp_notebook_example/subset_X_train.parquet'  # change to your X_train.parquet\n",
    "ENGINE = 'fastparquet'  \n",
    "NUM_SERIES = 100  # take first N series by id\n",
    "OUT_DIR = Path('./_wavelet21_outputs')\n",
    "OUT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Output files\n",
    "subset_parquet = OUT_DIR / 'wavelet_subset.parquet'\n",
    "out_pred_parquet = OUT_DIR / 'Wavelet21Predictors.parquet'\n",
    "out_meta_parquet = OUT_DIR / 'Wavelet21Metadata.parquet'\n",
    "out_pred_csv = OUT_DIR / 'Wavelet21Features.csv'\n",
    "\n",
    "print(f'Reading input: {INPUT_PARQUET}')\n",
    "df = pd.read_parquet(INPUT_PARQUET, engine=ENGINE)\n",
    "\n",
    "# Normalize to expected MultiIndex [id, time] with columns ['value','period'] if needed\n",
    "if not isinstance(df.index, pd.MultiIndex):\n",
    "    # Try to set index from columns if available\n",
    "    if {'id','time'}.issubset(df.columns):\n",
    "        df = df.set_index(['id','time']).sort_index()\n",
    "    else:\n",
    "        raise ValueError(\"Input must have a MultiIndex [id,time] or columns ['id','time'].\")\n",
    "\n",
    "# Validate required columns\n",
    "required_cols = {'value','period'}\n",
    "if not required_cols.issubset(df.columns):\n",
    "    raise ValueError(f\"Input must contain columns {required_cols}.\")\n",
    "\n",
    "# Select subset by first NUM_SERIES ids\n",
    "unique_ids = df.index.get_level_values('id').unique()\n",
    "subset_ids = list(unique_ids[: max(1, NUM_SERIES)])\n",
    "print(f'Selecting {len(subset_ids)} series (first ids): {subset_ids[:5]}{\" ...\" if len(subset_ids)>5 else \"\"}')\n",
    "\n",
    "df_subset = df.loc[pd.IndexSlice[subset_ids, :]].copy()\n",
    "print(f'Subset shape: {df_subset.shape}')\n",
    "\n",
    "# Persist subset to parquet for batch API\n",
    "df_subset.to_parquet(subset_parquet)\n",
    "print(f'Wrote subset to: {subset_parquet}')\n",
    "\n",
    "# Run Wavelet21 batch via high-level API\n",
    "from StructualBreakV2 import run_batch\n",
    "pred_df, meta_df = run_batch(\n",
    "    str(subset_parquet),\n",
    "    str(out_pred_parquet),\n",
    "    str(out_meta_parquet),\n",
    "    method='wavelet21'\n",
    ")\n",
    "\n",
    "# Also write a CSV of predictors like Roy24 example\n",
    "pred_df.to_csv(out_pred_csv, index=False)\n",
    "\n",
    "print('\\nOutputs:')\n",
    "print(f'  Predictors parquet: {out_pred_parquet}')\n",
    "print(f'  Metadata parquet:   {out_meta_parquet}')\n",
    "print(f'  Predictors CSV:     {out_pred_csv}')\n",
    "\n",
    "# Simple summary\n",
    "n_series = len(pred_df)\n",
    "n_success = int((meta_df.get('status') == 'success').sum()) if 'status' in meta_df.columns else None\n",
    "print(f\"\\nProcessed series: {n_series}\")\n",
    "if n_success is not None:\n",
    "    print(f\"Successful: {n_success}, Failed: {n_series - n_success}\")\n",
    "print('\\nPredictors head:')\n",
    "print(pred_df.head(3))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
